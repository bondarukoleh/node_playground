External app:
(App type)    Node -> Streaming -> Use a subshell? -> No -> fork 
              Non-Node:
(Interface type)        Streaming -> Use a subshell? -> No -> spawn
                        Buffered (callback) -> Use a subshell? -> No -> execFile
                                                                -> Yes -> exec
  The child_process module provides four different methods for executing external
applications. All methods are asynchronous. The right method will depend on
what you need, as shown in figure 8.1.
■ execFile—Execute an external application, given a set of arguments, and callback
with the buffered output after the process exits.
■ spawn—Execute an external application, given a set of arguments, and provide
a streaming interface for I/O and events for when the process exits.
■ exec—Execute one or more commands inside a shell and callback with the
buffered output after the process exits.
■ fork—Execute a Node module as a separate process, given a set of arguments,
provide a streaming and event-emitter interface like spawn, and also set up an interprocess
communication (IPC) channel between the parent and child process.

Windows/UNIX has a PATH environment variable. PATH contains a list of directories where executable programs
exist. If a program exists in one of the listed directories, it can be located without
needing an absolute or relative path to the application.


EXECFILE
If you need to execute a file without using a shell, the execFile function is what you need.
It behaves exactly like the exec function, but does not use a shell, which makes it a bit more efficient.

On Windows, some files cannot be executed on their own, like .bat or .cmd files.
Those files cannot be executed with execFile and you need "exec" or "spawn" with shell set to true to execute them.

The output from our external app is buffered internally. When our external app exits, our callback is called
with the output. exec behind the scenes will search for applications using PATH when no
absolute or relative location is provided. We can see this in our earlier example, since
directories to common system applications like echo usually exist in PATH already.
If the directory containing the application isn’t in PATH, you’ll need to provide the
location explicitly like you would on the command line:
cp.execFile('/absolute/path/to/app' ...
cp.execFile('../relative/path/to/app' ...
Add path before any execFile calls:
process.env.PATH += ':/a/new/path/to/executables';
ENOENT - app doesn't exist;
EACCES or EPERM error - exists but node cannot access it;

SPAWN
return Event Emitter API
The spawn function launches a command in a new process and we can use it to pass that command any arguments.
We can communicate with child directly from our stdin, to pass some data into child process.
const child = spawn('some_process');
process.stdin.pipe(child.stdin)
child.stdout.on('data', (data) => console.log(`child stdout:\n${data}`));

Same as execFile - but returns a stream that generates ChildProcess object, a ChildProcess object contains stdin,
stdout, and stderr stream objects.

EXEC
This method will spawn a subshell and execute the command in that shell and buffer generated data.
It buffers the command’s generated output and passes the whole output value to a callback function
(instead of using streams, which is what spawn does).

If you need to execute some full listed, with arguments as one string shell commands,
and if the size of the data expected from the command is small - you can use exec.
The exec method runs the commands with /bin/sh or cmd.exe (on Windows). Running commands in a shell
means you have access to all the functionality provided by your particular shell (like
pipes, redirects, and backgrounding).

Comparing to execFile and spawn, exec doesn’t have an args argument because exec allows us to execute
more than one command on a shell. When using exec, if we need to pass arguments to the command,
they should be part of the whole command string.

exec should be used when we need to utilize shell functionality such as pipe, redirects, backgrounding…

If we want to run command with arguments that user provides - it can be dangerous.
he  can provide something like xmllint --schema ; rm -rf / ; the.xml
";" - means start a new command.
If you need to run an application and don’t need shell facilities, it’s safer (and
slightly faster) to use execFile instead:
cp.execFile('xmllint', ['--schema', req.query.schema, 'the.xml']);
Here this malicious injection attack would fail since it’s not run in a shell and the external
application likely wouldn’t understand the argument and would raise an error.

DETACH a child process
Made to not be affected if this process will fail. It's like an different process.
You have a long-running external application that you want Node to start but then be
able to exit with the child process still running.

Attached child process exits when Node exits but Detached child process is process leader and lives
independent of Node.
Normally, any child process will be terminated when the parent Node process is terminated.
Child processes are said to be attached to the parent process. But the spawn
method includes the ability to detach a child process and promote it to be a process
group leader. In this scenario, if the parent is terminated, the child process will continue
until finished.
This scenario is useful when you want Node to set up the execution of a long running
external process and you don’t need Node to babysit it after it starts.
This is the detached option, configurable as part of a third options parameter to
spawn:
const detachedProcess = cp.spawn('./longrunApp', [], { detached: true });

The stdio option defines where the I/O from a child process will be redirected.
It takes either an array or a string as a value.The string values are simply shorthands that
will expand to common array configurations.
The array is structured such that the indexes correspond to file descriptors in the
child process and the values indicate where the I/O for the particular file descriptor
(FD) should be redirected.
By default, stdio is configured as
stdio: 'pipe'
which is a shorthand for the following array values:
stdio: [ 'pipe', 'pipe', 'pipe' ]

The pipe value connects the parent and child processes because these streams stay
open, waiting to write or read data. But sometimes, we want to disconnect the
two in order to exit the Node process. A brute-force approach would be to simply
destroy all the streams created:
child.stdin.destroy();
child.stdout.destroy();
child.stderr.destroy();
Although this would work, given our intent to not use them, it’s better to not create
the streams in the first place. Instead, we can assign a file descriptor if we want to
direct the I/O elsewhere or use ignore to discard it completely.

The child process will live on because it’s detached and the I/O is
disconnected from the parent. But the parent still has an internal reference to the
child process and won’t exit until the child process has finished and the reference has been removed.
You can use the child.unref() method to tell Node not to include this child process
reference in its count.

To make a completely separate child, detach a process requires three things:
■ The detached option must be set to true so the child becomes its own process leader.
■ The stdio option must be configured so the parent and child are disconnected.
■ The reference to the child must be disconnected in the parent using child.unref().

FORK
The fork function is a variation of the spawn function for spawning node processes.
The biggest difference between spawn and fork is that a communication channel is established to the child process
when using fork, so we can use the send function on the forked process along with the global process object
itself to exchange messages between the parent and forked processes. We do this through the EventEmitter
module interface.

We can use process.send() -> to speak to forked process directly. And vise versa - we can send messages from child
to parent

To made a big, computation heavily work (like webworker in browser), in separate process.
Running these types of tasks in a forked process allows the main application (a server for example) to stay responsive.
Another use of forking is for sharing file descriptors,
where a child can accept an incoming connection received by the parent process.

Node provides a nice way to communicate between other Node programs. Under
the hood, it sets up the following stdio configuration:
stdio: [ 0, 1, 2, 'ipc' ]
This means that, by default, all output and input are directly inherited from the parent;
there’s no child.stdin, child.stdout, or child.stderr:
const cp = require('child_process');
const child = cp.fork('./myChild');
So af far as I get - that means that child.stdout same as parent, you don't have access to it.
If you want to have 
const cp = require('child_process');
const child = cp.fork('./myChild', { silent: true }); // silent option gives you ability to have child.stdout.

The fork command runs a Node module in a separate process and sets up a communications
inter-process communication, IPC channel with parent.
The fork method opens up an IPC channel that allows message passing between Node
processes. On the child side, it exposes process.on('message') and process.send()
as mechanisms for receiving and sending messages. On the parent side, it provides
child.on('message') and child.send().

Sending data between the processes maintains the type information, which means you
can send any valid JSON value over the wire.
child.send(230);
child.send('a string');
child.send(true);
child.send(null);
child.send({ an: 'object' });

If you need to destroy channel with child child.disconnect(), it  only destroys connection,
not ended the child.
